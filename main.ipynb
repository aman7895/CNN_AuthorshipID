{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "import py_crepe\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "import data\n",
    "import string\n",
    "import pandas as pd\n",
    "np.random.seed(0123)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "subset = None\n",
    "\n",
    "#Whether to save model parameters\n",
    "save = False\n",
    "model_name_path = 'params/crepe_model.json'\n",
    "model_weights_path = 'params/crepe_model_weights.h5'\n",
    "\n",
    "#Maximum length. Longer gets chopped. Shorter gets padded.\n",
    "maxlen = 1014\n",
    "\n",
    "#Model params\n",
    "#Filters for conv layers\n",
    "nb_filter = 128 #initially 256\n",
    "#Number of units in the dense layer\n",
    "dense_outputs = 512 #Initially 1024\n",
    "#Conv layer kernel size\n",
    "filter_kernels = [7, 7, 3, 3, 3, 3]\n",
    "#Number of units in the final output layer. Number of classes.\n",
    "\n",
    "#Compile/fit params\n",
    "batch_size = 32\n",
    "nb_epoch = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 105\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (52983, 2)\n",
      "Author:  1078  Size:  4010\n",
      "Author:  1087  Size: 15538\n",
      "Author:  1416  Size: 33435\n",
      "Min: 4010\n",
      "Max: 33435\n",
      "Authors [1078, 1087, 1416].\n",
      "Found 12030 texts.\n",
      "Found 12030 labels.\n",
      "Creating vocab...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "#Expect x to be a list of sentences. Y to be a one-hot encoding of the\n",
    "#categories.\n",
    "\n",
    "### 515-1122-122 and 1573 with remove 6 layers\n",
    "#authorlist=[121, 479 , 649 ]\n",
    "#doc_id = 14706\n",
    "\n",
    "authorlist=[ 1078, 1087, 1416]\n",
    "doc_id = [ 2501, 2502, 2700, 2701, 3259, 3257 ]\n",
    "cat_output = len(authorlist) #binary in the last layer\n",
    "\n",
    "# def main(authorlist, doc_id):\n",
    "    \n",
    "    \n",
    "((trainX, trainY), (valX, valY)) = data_helpers.load_ag_data(authors = authorlist, docID = doc_id)\n",
    "\n",
    "print('Creating vocab...')\n",
    "vocab, reverse_vocab, vocab_size, check = data_helpers.create_vocab_set()\n",
    "\n",
    "\n",
    "#trainX = data_helpers.encode_data(trainX, maxlen, vocab, vocab_size, check)\n",
    "#test_data = data_helpers.encode_data(valX, maxlen, vocab, vocab_size, check)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "classes = len(authorlist)\n",
    "(model, sgd, model_weights_path) = py_crepe.build_model(classes, filter_kernels,\n",
    "                                                        dense_outputs, maxlen, vocab_size, nb_filter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model...\n",
      "Epoch: 0\n",
      "  Step: 100\n",
      "\tLoss: 1.03466424763. Accuracy: 0.45375\n",
      "  Step: 200\n",
      "\tLoss: 0.90203497529. Accuracy: 0.54828125\n",
      "  Step: 300\n",
      "\tLoss: 0.823189590971. Accuracy: 0.603333333333\n",
      "Epoch 0. Loss: 0.547141330807. Accuracy: 0.776178727809\n",
      "Epoch time: 0:06:12.654796. Total time: 0:06:12.913420\n",
      "\n",
      "Epoch: 1\n",
      "  Step: 100\n",
      "\tLoss: 0.522652076781. Accuracy: 0.7578125\n",
      "  Step: 200\n",
      "\tLoss: 0.513188425899. Accuracy: 0.7609375\n",
      "  Step: 300\n",
      "\tLoss: 0.502541306913. Accuracy: 0.767083333333\n",
      "Epoch 1. Loss: 0.45341364059. Accuracy: 0.784676535349\n",
      "Epoch time: 0:05:52.388172. Total time: 0:12:05.558098\n",
      "\n",
      "Epoch: 2\n",
      "  Step: 100\n",
      "\tLoss: 0.412180459946. Accuracy: 0.8240625\n",
      "  Step: 200\n",
      "\tLoss: 0.402938581072. Accuracy: 0.82375\n",
      "  Step: 300\n",
      "\tLoss: 0.385770478174. Accuracy: 0.832604166667\n",
      "Epoch 2. Loss: 0.419714071445. Accuracy: 0.811266447368\n",
      "Epoch time: 0:06:00.975220. Total time: 0:18:06.783919\n",
      "\n",
      "Epoch: 3\n",
      "  Step: 100\n",
      "\tLoss: 0.291129405946. Accuracy: 0.884375\n",
      "  Step: 200\n",
      "\tLoss: 0.290412117075. Accuracy: 0.883125\n",
      "  Step: 300\n",
      "\tLoss: 0.282817968863. Accuracy: 0.886041666667\n",
      "Epoch 3. Loss: 0.467714625166. Accuracy: 0.798108552632\n",
      "Epoch time: 0:05:59.961705. Total time: 0:24:06.994282\n",
      "\n",
      "Epoch: 4\n",
      "  Step: 100\n",
      "\tLoss: 0.183539234959. Accuracy: 0.9359375\n",
      "  Step: 200\n",
      "\tLoss: 0.187296935301. Accuracy: 0.93015625\n",
      "  Step: 300\n",
      "\tLoss: 0.17996562168. Accuracy: 0.931875\n",
      "Epoch 4. Loss: 0.42454239628. Accuracy: 0.8359375\n",
      "Epoch time: 0:05:52.910690. Total time: 0:30:00.131161\n",
      "\n",
      "Epoch: 5\n",
      "  Step: 100\n",
      "\tLoss: 0.0835129139386. Accuracy: 0.9725\n",
      "  Step: 200\n",
      "\tLoss: 0.0856012852513. Accuracy: 0.97234375\n",
      "  Step: 300\n",
      "\tLoss: 0.0842126558364. Accuracy: 0.973854166667\n",
      "Epoch 5. Loss: 0.498429055375. Accuracy: 0.828673245875\n",
      "Epoch time: 0:05:51.982648. Total time: 0:35:52.346431\n",
      "\n",
      "Epoch: 6\n",
      "  Step: 100\n",
      "\tLoss: 0.0405304833641. Accuracy: 0.99\n",
      "  Step: 200\n",
      "\tLoss: 0.0410962215159. Accuracy: 0.99\n",
      "  Step: 300\n",
      "\tLoss: 0.0408591711087. Accuracy: 0.989895833333\n",
      "Epoch 6. Loss: 0.448049011836. Accuracy: 0.844846490967\n",
      "Epoch time: 0:05:54.390772. Total time: 0:41:46.971446\n",
      "\n",
      "Epoch: 7\n",
      "  Step: 100\n",
      "\tLoss: 0.0209882606519. Accuracy: 0.9959375\n",
      "  Step: 200\n",
      "\tLoss: 0.0239030323655. Accuracy: 0.99484375\n",
      "  Step: 300\n",
      "\tLoss: 0.021806564579. Accuracy: 0.995416666667\n",
      "Epoch 7. Loss: 0.544245730105. Accuracy: 0.83950109623\n",
      "Epoch time: 0:05:51.495897. Total time: 0:47:38.697749\n",
      "\n",
      "Epoch: 8\n",
      "  Step: 100\n",
      "\tLoss: 0.0155629889783. Accuracy: 0.9971875\n",
      "  Step: 200\n",
      "\tLoss: 0.012646504018. Accuracy: 0.99765625\n",
      "  Step: 300\n",
      "\tLoss: 0.0117477019154. Accuracy: 0.998020833333\n",
      "Epoch 8. Loss: 0.543781593252. Accuracy: 0.845394736842\n",
      "Epoch time: 0:05:51.948952. Total time: 0:53:30.880873\n",
      "\n",
      "Epoch: 9\n",
      "  Step: 100\n",
      "\tLoss: 0.00584130766278. Accuracy: 0.9996875\n",
      "  Step: 200\n",
      "\tLoss: 0.0053004260853. Accuracy: 0.9996875\n",
      "  Step: 300\n",
      "\tLoss: 0.00601355460734. Accuracy: 0.999375\n",
      "Epoch 9. Loss: 0.559400604327. Accuracy: 0.848410087981\n",
      "Epoch time: 0:05:50.308249. Total time: 0:59:21.424082\n",
      "\n",
      "Epoch: 10\n",
      "  Step: 100\n",
      "\tLoss: 0.00326959828031. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00342165090799. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00375555012569. Accuracy: 1.0\n",
      "Epoch 10. Loss: 0.56794173545. Accuracy: 0.856496710526\n",
      "Epoch time: 0:05:53.044511. Total time: 1:05:14.699760\n",
      "\n",
      "Epoch: 11\n",
      "  Step: 100\n",
      "\tLoss: 0.00249687141331. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00208566727422. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00253098154722. Accuracy: 1.0\n",
      "Epoch 11. Loss: 0.644383459009. Accuracy: 0.850191885703\n",
      "Epoch time: 0:05:51.249288. Total time: 1:11:06.177576\n",
      "\n",
      "Epoch: 12\n",
      "  Step: 100\n",
      "\tLoss: 0.002711435159. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00227973863963. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00220434669114. Accuracy: 1.0\n",
      "Epoch 12. Loss: 0.63514079281. Accuracy: 0.851425438335\n",
      "Epoch time: 0:05:53.064682. Total time: 1:16:59.472649\n",
      "\n",
      "Epoch: 13\n",
      "  Step: 100\n",
      "\tLoss: 0.00161930580281. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00146236628065. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00144229494722. Accuracy: 1.0\n",
      "Epoch 13. Loss: 0.623734138205. Accuracy: 0.8515625\n",
      "Epoch time: 0:05:52.467824. Total time: 1:22:52.173981\n",
      "\n",
      "Epoch: 14\n",
      "  Step: 100\n",
      "\tLoss: 0.00105659419423. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00119113041575. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00118914961589. Accuracy: 1.0\n",
      "Epoch 14. Loss: 0.668151708418. Accuracy: 0.848958333072\n",
      "Epoch time: 0:05:52.381887. Total time: 1:28:44.790798\n",
      "\n",
      "Epoch: 15\n",
      "  Step: 100\n",
      "\tLoss: 0.00116774370916. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.0013361375286. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00122351199653. Accuracy: 1.0\n",
      "Epoch 15. Loss: 0.659544889374. Accuracy: 0.847176535349\n",
      "Epoch time: 0:05:53.174170. Total time: 1:34:38.199995\n",
      "\n",
      "Epoch: 16\n",
      "  Step: 100\n",
      "\tLoss: 0.000962550559634. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00109566880259. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00111382531686. Accuracy: 1.0\n",
      "Epoch 16. Loss: 0.710197561292. Accuracy: 0.842242324823\n",
      "Epoch time: 0:05:52.393325. Total time: 1:40:30.820798\n",
      "\n",
      "Epoch: 17\n",
      "  Step: 100\n",
      "\tLoss: 0.0012798768466. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00114219258365. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.0010479569617. Accuracy: 1.0\n",
      "Epoch 17. Loss: 0.668935645274. Accuracy: 0.849369517282\n",
      "Epoch time: 0:05:53.424150. Total time: 1:46:24.474886\n",
      "\n",
      "Epoch: 18\n",
      "  Step: 100\n",
      "\tLoss: 0.00215815414653. Accuracy: 0.9996875\n",
      "  Step: 200\n",
      "\tLoss: 0.00166586742303. Accuracy: 0.99984375\n",
      "  Step: 300\n",
      "\tLoss: 0.00152824561495. Accuracy: 0.999895833333\n",
      "Epoch 18. Loss: 0.665529944101. Accuracy: 0.851425438335\n",
      "Epoch time: 0:05:51.580532. Total time: 1:52:16.287915\n",
      "\n",
      "Epoch: 19\n",
      "  Step: 100\n",
      "\tLoss: 0.0012563569636. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00101594292966. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000906300025454. Accuracy: 1.0\n",
      "Epoch 19. Loss: 0.672119295519. Accuracy: 0.849917763158\n",
      "Epoch time: 0:05:55.939786. Total time: 1:58:12.454926\n",
      "\n",
      "Epoch: 20\n",
      "  Step: 100\n",
      "\tLoss: 0.000739829775302. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000884776453167. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000907442458762. Accuracy: 1.0\n",
      "Epoch 20. Loss: 0.657728881722. Accuracy: 0.851014254125\n",
      "Epoch time: 0:05:52.241847. Total time: 2:04:04.923596\n",
      "\n",
      "Epoch: 21\n",
      "  Step: 100\n",
      "\tLoss: 0.00100209414404. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000913626727661. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00084407662127. Accuracy: 1.0\n",
      "Epoch 21. Loss: 0.676318729125. Accuracy: 0.856496710526\n",
      "Epoch time: 0:05:56.179417. Total time: 2:10:01.339597\n",
      "\n",
      "Epoch: 22\n",
      "  Step: 100\n",
      "\tLoss: 0.000656628341603. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000605465059762. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000677512745072. Accuracy: 1.0\n",
      "Epoch 22. Loss: 0.674592987193. Accuracy: 0.851151315789\n",
      "Epoch time: 0:05:53.699437. Total time: 2:15:55.267103\n",
      "\n",
      "Epoch: 23\n",
      "  Step: 100\n",
      "\tLoss: 0.000377976016971. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000517708799562. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000477536278261. Accuracy: 1.0\n",
      "Epoch 23. Loss: 0.694864743193. Accuracy: 0.849780701493\n",
      "Epoch time: 0:05:56.606256. Total time: 2:21:52.104420\n",
      "\n",
      "Epoch: 24\n",
      "  Step: 100\n",
      "\tLoss: 0.000584605899094. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000797829276144. Accuracy: 0.99984375\n",
      "  Step: 300\n",
      "\tLoss: 0.000759310938301. Accuracy: 0.999895833333\n",
      "Epoch 24. Loss: 0.756385772924. Accuracy: 0.844983552632\n",
      "Epoch time: 0:05:51.836619. Total time: 2:27:44.167401\n",
      "\n",
      "Epoch: 25\n",
      "  Step: 100\n",
      "\tLoss: 0.000443897059777. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000540907468048. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000489293999714. Accuracy: 1.0\n",
      "Epoch 25. Loss: 0.712484032896. Accuracy: 0.850191885703\n",
      "Epoch time: 0:05:56.108544. Total time: 2:33:40.508883\n",
      "\n",
      "Epoch: 26\n",
      "  Step: 100\n",
      "\tLoss: 0.000470142885079. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000512607761802. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000502608742845. Accuracy: 1.0\n",
      "Epoch 26. Loss: 0.694196233405. Accuracy: 0.8515625\n",
      "Epoch time: 0:05:51.115480. Total time: 2:39:31.852365\n",
      "\n",
      "Epoch: 27\n",
      "  Step: 100\n",
      "\tLoss: 0.000810563032828. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000612032106355. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000532706453505. Accuracy: 1.0\n",
      "Epoch 27. Loss: 0.729364840608. Accuracy: 0.849232456402\n",
      "Epoch time: 0:05:56.459837. Total time: 2:45:28.549999\n",
      "\n",
      "Epoch: 28\n",
      "  Step: 100\n",
      "\tLoss: 0.000846383348508. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000642845347938. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000578648324299. Accuracy: 1.0\n",
      "Epoch 28. Loss: 0.713097122351. Accuracy: 0.847450657895\n",
      "Epoch time: 0:05:53.875397. Total time: 2:51:22.650578\n",
      "\n",
      "Epoch: 29\n",
      "  Step: 100\n",
      "\tLoss: 0.000365849938898. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000430580327129. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000437572554201. Accuracy: 1.0\n",
      "Epoch 29. Loss: 0.709393645245. Accuracy: 0.853207236842\n",
      "Epoch time: 0:05:55.523190. Total time: 2:57:18.398290\n",
      "\n",
      "Epoch: 30\n",
      "  Step: 100\n",
      "\tLoss: 0.00049963560592. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000442044416777. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000419733075093. Accuracy: 1.0\n",
      "Epoch 30. Loss: 0.748935218606. Accuracy: 0.847176535349\n",
      "Epoch time: 0:05:50.964388. Total time: 3:03:09.601179\n",
      "\n",
      "Epoch: 31\n",
      "  Step: 100\n",
      "\tLoss: 0.000659371632264. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000517825525094. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000460739651756. Accuracy: 1.0\n",
      "Epoch 31. Loss: 0.717108380022. Accuracy: 0.851973684211\n",
      "Epoch time: 0:05:55.618065. Total time: 3:09:05.447658\n",
      "\n",
      "Epoch: 32\n",
      "  Step: 100\n",
      "\tLoss: 0.000428632486128. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000370739143673. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000345462797929. Accuracy: 1.0\n",
      "Epoch 32. Loss: 0.755976950088. Accuracy: 0.846354166928\n",
      "Epoch time: 0:05:52.176972. Total time: 3:14:57.851692\n",
      "\n",
      "Epoch: 33\n",
      "  Step: 100\n",
      "\tLoss: 0.000294551314855. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000282633272482. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000283964057477. Accuracy: 1.0\n",
      "Epoch 33. Loss: 0.73605566233. Accuracy: 0.847861842105\n",
      "Epoch time: 0:05:58.247765. Total time: 3:20:56.332149\n",
      "\n",
      "Epoch: 34\n",
      "  Step: 100\n",
      "\tLoss: 0.000272767098922. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000253347670887. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000284648133493. Accuracy: 1.0\n",
      "Epoch 34. Loss: 0.752787096818. Accuracy: 0.844161184211\n",
      "Epoch time: 0:05:53.857359. Total time: 3:26:50.415913\n",
      "\n",
      "Epoch: 35\n",
      "  Step: 100\n",
      "\tLoss: 0.000188256528045. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00026212561274. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000290589066917. Accuracy: 1.0\n",
      "Epoch 35. Loss: 0.765261286735. Accuracy: 0.847176535349\n",
      "Epoch time: 0:05:53.763623. Total time: 3:32:44.411740\n",
      "\n",
      "Epoch: 36\n",
      "  Step: 100\n",
      "\tLoss: 0.000296308946727. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000257301733661. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000260755597678. Accuracy: 1.0\n",
      "Epoch 36. Loss: 0.737721261103. Accuracy: 0.854440789474\n",
      "Epoch time: 0:05:55.064662. Total time: 3:38:39.702882\n",
      "\n",
      "Epoch: 37\n",
      "  Step: 100\n",
      "\tLoss: 0.000231251662935. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000350933512591. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000388776076995. Accuracy: 1.0\n",
      "Epoch 37. Loss: 0.744016586264. Accuracy: 0.851836622546\n",
      "Epoch time: 0:05:54.718303. Total time: 3:44:34.653386\n",
      "\n",
      "Epoch: 38\n",
      "  Step: 100\n",
      "\tLoss: 0.000270662038856. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000258998856464. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000265534687346. Accuracy: 1.0\n",
      "Epoch 38. Loss: 0.762391040298. Accuracy: 0.848410087981\n",
      "Epoch time: 0:05:52.626816. Total time: 3:50:27.519774\n",
      "\n",
      "Epoch: 39\n",
      "  Step: 100\n",
      "\tLoss: 0.000352179362499. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00027201623941. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000290074916335. Accuracy: 1.0\n",
      "Epoch 39. Loss: 0.795099029023. Accuracy: 0.846080043598\n",
      "Epoch time: 0:05:56.755329. Total time: 3:56:24.508523\n",
      "\n",
      "Epoch: 40\n",
      "  Step: 100\n",
      "\tLoss: 0.000272107459787. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000317346875613. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000290524436232. Accuracy: 1.0\n",
      "Epoch 40. Loss: 0.753145921093. Accuracy: 0.851836622546\n",
      "Epoch time: 0:05:53.545978. Total time: 4:02:18.283155\n",
      "\n",
      "Epoch: 41\n",
      "  Step: 100\n",
      "\tLoss: 0.000308955735945. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000242164200099. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000227545126891. Accuracy: 1.0\n",
      "Epoch 41. Loss: 0.760358501814. Accuracy: 0.84758771956\n",
      "Epoch time: 0:05:56.149265. Total time: 4:08:14.668234\n",
      "\n",
      "Epoch: 42\n",
      "  Step: 100\n",
      "\tLoss: 0.000179652423903. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00017375849907. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000203969881779. Accuracy: 1.0\n",
      "Epoch 42. Loss: 0.760253460441. Accuracy: 0.852247806756\n",
      "Epoch time: 0:05:52.684604. Total time: 4:14:07.584673\n",
      "\n",
      "Epoch: 43\n",
      "  Step: 100\n",
      "\tLoss: 0.000201536012601. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000201286442139. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000197760306731. Accuracy: 1.0\n",
      "Epoch 43. Loss: 0.768245847013. Accuracy: 0.848135964651\n",
      "Epoch time: 0:05:57.457518. Total time: 4:20:05.274391\n",
      "\n",
      "Epoch: 44\n",
      "  Step: 100\n",
      "\tLoss: 0.000242148207726. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000225387524852. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000228689163766. Accuracy: 1.0\n",
      "Epoch 44. Loss: 0.749102996466. Accuracy: 0.854851973684\n",
      "Epoch time: 0:05:52.778950. Total time: 4:25:58.281012\n",
      "\n",
      "Epoch: 45\n",
      "  Step: 100\n",
      "\tLoss: 0.000145891592701. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000179214156447. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00017075953648. Accuracy: 1.0\n",
      "Epoch 45. Loss: 0.808435960477. Accuracy: 0.845942982718\n",
      "Epoch time: 0:05:55.770862. Total time: 4:31:54.279768\n",
      "\n",
      "Epoch: 46\n",
      "  Step: 100\n",
      "\tLoss: 0.000122880479366. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000179235825342. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000168072939179. Accuracy: 1.0\n",
      "Epoch 46. Loss: 0.762856754131. Accuracy: 0.851973684211\n",
      "Epoch time: 0:05:54.218273. Total time: 4:37:48.734414\n",
      "\n",
      "Epoch: 47\n",
      "  Step: 100\n",
      "\tLoss: 0.000147220756253. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00015054431035. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000160065361985. Accuracy: 1.0\n",
      "Epoch 47. Loss: 0.767579840882. Accuracy: 0.853618421053\n",
      "Epoch time: 0:05:56.527802. Total time: 4:43:45.492225\n",
      "\n",
      "Epoch: 48\n",
      "  Step: 100\n",
      "\tLoss: 0.000173236394758. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.00018622381775. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000180512903128. Accuracy: 1.0\n",
      "Epoch 48. Loss: 0.787333353913. Accuracy: 0.849643640612\n",
      "Epoch time: 0:05:53.453662. Total time: 4:49:39.172686\n",
      "\n",
      "Epoch: 49\n",
      "  Step: 100\n",
      "\tLoss: 0.000266315906392. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000194494687394. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000188659697909. Accuracy: 1.0\n",
      "Epoch 49. Loss: 0.768385741471. Accuracy: 0.8515625\n",
      "Epoch time: 0:05:55.646600. Total time: 4:55:35.046972\n",
      "\n",
      "Epoch: 50\n",
      "  Step: 100\n",
      "\tLoss: 0.000166712429391. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000144145285399. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00016013652092. Accuracy: 1.0\n",
      "Epoch 50. Loss: 0.797804800205. Accuracy: 0.846902412019\n",
      "Epoch time: 0:05:54.365782. Total time: 5:01:29.646355\n",
      "\n",
      "Epoch: 51\n",
      "  Step: 100\n",
      "\tLoss: 0.000197777371159. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000170197856555. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000166988742928. Accuracy: 1.0\n",
      "Epoch 51. Loss: 0.780685890858. Accuracy: 0.846217105263\n",
      "Epoch time: 0:05:57.221205. Total time: 5:07:27.101239\n",
      "\n",
      "Epoch: 52\n",
      "  Step: 100\n",
      "\tLoss: 0.000146004078997. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000150193212512. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000137394405692. Accuracy: 1.0\n",
      "Epoch 52. Loss: 0.788603200485. Accuracy: 0.850191885703\n",
      "Epoch time: 0:05:52.972482. Total time: 5:13:20.301325\n",
      "\n",
      "Epoch: 53\n",
      "  Step: 100\n",
      "\tLoss: 0.000194527726999. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000140406300925. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000146634649221. Accuracy: 1.0\n",
      "Epoch 53. Loss: 0.775403477383. Accuracy: 0.851151315789\n",
      "Epoch time: 0:05:54.841587. Total time: 5:19:15.372475\n",
      "\n",
      "Epoch: 54\n",
      "  Step: 100\n",
      "\tLoss: 0.000149215224928. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000165308980334. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000168178442348. Accuracy: 1.0\n",
      "Epoch 54. Loss: 0.799202772151. Accuracy: 0.851014254125\n",
      "Epoch time: 0:05:52.940897. Total time: 5:25:08.543595\n",
      "\n",
      "Epoch: 55\n",
      "  Step: 100\n",
      "\tLoss: 0.000165147018115. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000138707107717. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000140835081162. Accuracy: 1.0\n",
      "Epoch 55. Loss: 0.792629451932. Accuracy: 0.848958333072\n",
      "Epoch time: 0:05:54.478871. Total time: 5:31:03.250527\n",
      "\n",
      "Epoch: 56\n",
      "  Step: 100\n",
      "\tLoss: 0.00014356807581. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000146272455099. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000145161266929. Accuracy: 1.0\n",
      "Epoch 56. Loss: 0.774842768025. Accuracy: 0.851014254125\n",
      "Epoch time: 0:05:53.598294. Total time: 5:36:57.089111\n",
      "\n",
      "Epoch: 57\n",
      "  Step: 100\n",
      "\tLoss: 0.000138716283996. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000126100499267. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000128665571081. Accuracy: 1.0\n",
      "Epoch 57. Loss: 0.783839543669. Accuracy: 0.8515625\n",
      "Epoch time: 0:05:55.755222. Total time: 5:42:53.073192\n",
      "\n",
      "Epoch: 58\n",
      "  Step: 100\n",
      "\tLoss: 0.000135469115357. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000125676244199. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000125823520123. Accuracy: 1.0\n",
      "Epoch 58. Loss: 0.793132523933. Accuracy: 0.850603069914\n",
      "Epoch time: 0:05:52.176939. Total time: 5:48:45.476118\n",
      "\n",
      "Epoch: 59\n",
      "  Step: 100\n",
      "\tLoss: 0.000137031142003. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000122809736135. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000123409361957. Accuracy: 1.0\n",
      "Epoch 59. Loss: 0.798164958526. Accuracy: 0.84799890377\n",
      "Epoch time: 0:05:54.449002. Total time: 5:54:40.153984\n",
      "\n",
      "Epoch: 60\n",
      "  Step: 100\n",
      "\tLoss: 9.62658058734e-05. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000107968816556. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000110749239423. Accuracy: 1.0\n",
      "Epoch 60. Loss: 0.794647129302. Accuracy: 0.851425438335\n",
      "Epoch time: 0:05:51.681743. Total time: 6:00:32.064473\n",
      "\n",
      "Epoch: 61\n",
      "  Step: 100\n",
      "\tLoss: 0.0002351978345. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000173364431603. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000150187019817. Accuracy: 1.0\n",
      "Epoch 61. Loss: 0.789932426898. Accuracy: 0.850328947368\n",
      "Epoch time: 0:05:53.146088. Total time: 6:06:25.453081\n",
      "\n",
      "Epoch: 62\n",
      "  Step: 100\n",
      "\tLoss: 0.000137449622889. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000121742532233. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000126767975395. Accuracy: 1.0\n",
      "Epoch 62. Loss: 0.791043577863. Accuracy: 0.850603069914\n",
      "Epoch time: 0:05:53.007393. Total time: 6:12:18.689417\n",
      "\n",
      "Epoch: 63\n",
      "  Step: 100\n",
      "\tLoss: 0.000150750012322. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000122883656906. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.00013251647451. Accuracy: 1.0\n",
      "Epoch 63. Loss: 0.834927788494. Accuracy: 0.853755482718\n",
      "Epoch time: 0:05:54.498851. Total time: 6:18:13.417121\n",
      "\n",
      "Epoch: 64\n",
      "  Step: 100\n",
      "\tLoss: 9.93064402064e-05. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 9.98224002024e-05. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000139588641764. Accuracy: 1.0\n",
      "Epoch 64. Loss: 0.808161880184. Accuracy: 0.852384868421\n",
      "Epoch time: 0:05:52.816949. Total time: 6:24:06.472290\n",
      "\n",
      "Epoch: 65\n",
      "  Step: 100\n",
      "\tLoss: 0.000125368312852. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000117179136817. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000108533279758. Accuracy: 1.0\n",
      "Epoch 65. Loss: 0.803848351401. Accuracy: 0.851014254125\n",
      "Epoch time: 0:05:55.560613. Total time: 6:30:02.260849\n",
      "\n",
      "Epoch: 66\n",
      "  Step: 100\n",
      "\tLoss: 9.32679748848e-05. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000102257958704. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000100404464733. Accuracy: 1.0\n",
      "Epoch 66. Loss: 0.795467948296. Accuracy: 0.853207236842\n",
      "Epoch time: 0:05:52.978290. Total time: 6:35:55.465723\n",
      "\n",
      "Epoch: 67\n",
      "  Step: 100\n",
      "\tLoss: 0.000105124016982. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000140909357779. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000136417927608. Accuracy: 1.0\n",
      "Epoch 67. Loss: 0.799806365792. Accuracy: 0.849232456402\n",
      "Epoch time: 0:05:53.401670. Total time: 6:41:49.110840\n",
      "\n",
      "Epoch: 68\n",
      "  Step: 100\n",
      "\tLoss: 0.000121274521412. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000118569377573. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000114603625367. Accuracy: 1.0\n",
      "Epoch 68. Loss: 0.791934225512. Accuracy: 0.848958333072\n",
      "Epoch time: 0:05:53.747895. Total time: 6:47:43.093185\n",
      "\n",
      "Epoch: 69\n",
      "  Step: 100\n",
      "\tLoss: 0.000169454713805. Accuracy: 1.0\n",
      "  Step: 200\n",
      "\tLoss: 0.000143599640944. Accuracy: 1.0\n",
      "  Step: 300\n",
      "\tLoss: 0.000136487213073. Accuracy: 1.0\n",
      "Epoch 69. Loss: 0.79044480128. Accuracy: 0.852796052632\n",
      "Epoch time: 0:05:55.692492. Total time: 6:53:39.014769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fit model...')\n",
    "initial = datetime.datetime.now()\n",
    "for e in xrange(nb_epoch):\n",
    "    xi, yi = data_helpers.shuffle_matrix(trainX, trainY)\n",
    "    xi_test, yi_test = data_helpers.shuffle_matrix(valX, valY)\n",
    "    if subset:\n",
    "        batches = data_helpers.mini_batch_generator(xi[:subset], yi[:subset],\n",
    "                                                    vocab, vocab_size, check,\n",
    "                                                    maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "    else:\n",
    "        batches = data_helpers.mini_batch_generator(xi, yi, vocab, vocab_size,\n",
    "                                                    check, maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "    test_batches = data_helpers.mini_batch_generator(xi_test, yi_test, vocab,\n",
    "                                                     vocab_size, check, maxlen,\n",
    "                                                     batch_size=batch_size)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    loss = 0.0\n",
    "    step = 1\n",
    "    start = datetime.datetime.now()\n",
    "    print('Epoch: {}'.format(e))\n",
    "    for x_train, y_train in batches:\n",
    "        \n",
    "        f = model.train_on_batch(x_train, y_train)\n",
    "        loss += f[0]\n",
    "        loss_avg = loss / step\n",
    "        accuracy += f[1]\n",
    "        accuracy_avg = accuracy / step\n",
    "        if step % 100 == 0:\n",
    "            print('  Step: {}'.format(step))\n",
    "            print('\\tLoss: {}. Accuracy: {}'.format(loss_avg, accuracy_avg))\n",
    "        step += 1\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_step = 1\n",
    "    \n",
    "    for x_test_batch, y_test_batch in test_batches:\n",
    "        f_ev = model.test_on_batch(x_test_batch, y_test_batch)\n",
    "        test_loss += f_ev[0]\n",
    "        test_loss_avg = test_loss / test_step\n",
    "        test_accuracy += f_ev[1]\n",
    "        test_accuracy_avg = test_accuracy / test_step\n",
    "        test_step += 1\n",
    "    stop = datetime.datetime.now()\n",
    "    e_elap = stop - start\n",
    "    t_elap = stop - initial\n",
    "    print('Epoch {}. Loss: {}. Accuracy: {}\\nEpoch time: {}. Total time: {}\\n'.format(e, test_loss_avg, test_accuracy_avg, e_elap, t_elap))\n",
    "\n",
    "if save:\n",
    "    print('Saving model params...')\n",
    "    json_string = model.to_json()\n",
    "    with open(model_name_path, 'w') as f:\n",
    "        json.dump(json_string, f)\n",
    "\n",
    "model.save_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del trainX, trainY, valX, valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_weights_path)\n",
    "\n",
    "#from keras.optimizers import SGD\n",
    "#sgd = SGD(lr=0.01, momentum=0.9, nesterov= True)\n",
    "\n",
    "# Compile model again (required to make predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_binary = []\n",
    "for docs in doc_id:\n",
    "    (testX, testY) = data_helpers.load_doc_data(authors = authorlist, docID = docs)\n",
    "    testX = data_helpers.encode_data(testX, maxlen, vocab, vocab_size, check)\n",
    "    predY = np.array(model.predict(testX, batch_size=batch_size))\n",
    "    testY = np.array(testY)\n",
    "    predY = predY.mean(axis = 0)\n",
    "    testY = testY.mean(axis = 0)\n",
    "    predLocation = predY.tolist().index(max(predY))\n",
    "    if predLocation == testY:\n",
    "        test_binary.append(1)\n",
    "    else:\n",
    "        test_binary.append(0)\n",
    "    \n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predY = np.array(model.predict(testX, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predY.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature_model = py_crepe.build_feature_model()\n",
    "feature_trainX = feature_model.predict(trainX)\n",
    "feature_testX = feature_model.predict(testX)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
