{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "import py_crepe\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "import data\n",
    "import string\n",
    "import pandas as pd\n",
    "np.random.seed(0123)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "subset = None\n",
    "\n",
    "#Whether to save model parameters\n",
    "save = False\n",
    "model_name_path = 'params/crepe_model.json'\n",
    "model_weights_path = 'params/crepe_model_weights.h5'\n",
    "\n",
    "#Maximum length. Longer gets chopped. Shorter gets padded.\n",
    "maxlen = 1014\n",
    "\n",
    "#Model params\n",
    "#Filters for conv layers\n",
    "nb_filter = 128 #initially 256\n",
    "#Number of units in the dense layer\n",
    "dense_outputs = 512 #Initially 1024\n",
    "#Conv layer kernel size\n",
    "filter_kernels = [7, 7, 3, 3, 3, 3]\n",
    "#Number of units in the final output layer. Number of classes.\n",
    "\n",
    "#Compile/fit params\n",
    "batch_size = 32\n",
    "nb_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 70\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (20370, 2)\n",
      "Author:    55  Size:  2701\n",
      "Author:    75  Size: 13694\n",
      "Author:    80  Size:  3975\n",
      "Min: 2701\n",
      "Max: 13694\n",
      "Authors [55, 75, 80].\n",
      "Found 8103 texts.\n",
      "Found 8103 labels.\n",
      "Creating vocab...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "#Expect x to be a list of sentences. Y to be a one-hot encoding of the\n",
    "#categories.\n",
    "\n",
    "### 515-1122-122 and 1573 with remove 6 layers\n",
    "#authorlist=[121, 479 , 649 ]\n",
    "#doc_id = 14706\n",
    "\n",
    "authorlist=[ 55, 75, 80]\n",
    "doc_id = 80\n",
    "cat_output = len(authorlist) #binary in the last layer\n",
    "\n",
    "# def main(authorlist, doc_id):\n",
    "    \n",
    "    \n",
    "((trainX, trainY), (valX, valY)) = data_helpers.load_ag_data(authors = authorlist, docID = doc_id)\n",
    "\n",
    "print('Creating vocab...')\n",
    "vocab, reverse_vocab, vocab_size, check = data_helpers.create_vocab_set()\n",
    "\n",
    "\n",
    "#trainX = data_helpers.encode_data(trainX, maxlen, vocab, vocab_size, check)\n",
    "#test_data = data_helpers.encode_data(valX, maxlen, vocab, vocab_size, check)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "classes = len(authorlist)\n",
    "(model, sgd) = py_crepe.model(classes, filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model...\n",
      "Epoch: 0\n",
      "  Step: 100\n",
      "\tLoss: 0.764290315956. Accuracy: 0.6571875\n",
      "  Step: 200\n",
      "\tLoss: 0.519613031894. Accuracy: 0.779375\n",
      "Epoch 0. Loss: 0.24589606758. Accuracy: 0.902865312847\n",
      "Epoch time: 0:09:59.219471. Total time: 0:09:59.382526\n",
      "\n",
      "Epoch: 1\n",
      "  Step: 100\n",
      "\tLoss: 0.203406570442. Accuracy: 0.92375\n",
      "  Step: 200\n",
      "\tLoss: 0.194800769584. Accuracy: 0.92640625\n",
      "Epoch 1. Loss: 0.168923568346. Accuracy: 0.947274743342\n",
      "Epoch time: 0:09:54.631171. Total time: 0:19:54.184923\n",
      "\n",
      "Epoch: 2\n",
      "  Step: 100\n",
      "\tLoss: 0.125617066966. Accuracy: 0.95\n",
      "  Step: 200\n",
      "\tLoss: 0.12723420152. Accuracy: 0.95203125\n",
      "Epoch 2. Loss: 0.207729942804. Accuracy: 0.924924136377\n",
      "Epoch time: 0:09:36.873742. Total time: 0:29:31.210857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fit model...')\n",
    "initial = datetime.datetime.now()\n",
    "for e in xrange(nb_epoch):\n",
    "    xi, yi = data_helpers.shuffle_matrix(trainX, trainY)\n",
    "    xi_test, yi_test = data_helpers.shuffle_matrix(valX, valY)\n",
    "    if subset:\n",
    "        batches = data_helpers.mini_batch_generator(xi[:subset], yi[:subset],\n",
    "                                                    vocab, vocab_size, check,\n",
    "                                                    maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "    else:\n",
    "        batches = data_helpers.mini_batch_generator(xi, yi, vocab, vocab_size,\n",
    "                                                    check, maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "    test_batches = data_helpers.mini_batch_generator(xi_test, yi_test, vocab,\n",
    "                                                     vocab_size, check, maxlen,\n",
    "                                                     batch_size=batch_size)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    loss = 0.0\n",
    "    step = 1\n",
    "    start = datetime.datetime.now()\n",
    "    print('Epoch: {}'.format(e))\n",
    "    for x_train, y_train in batches:\n",
    "        \n",
    "        f = model.train_on_batch(x_train, y_train)\n",
    "        loss += f[0]\n",
    "        loss_avg = loss / step\n",
    "        accuracy += f[1]\n",
    "        accuracy_avg = accuracy / step\n",
    "        if step % 100 == 0:\n",
    "            print('  Step: {}'.format(step))\n",
    "            print('\\tLoss: {}. Accuracy: {}'.format(loss_avg, accuracy_avg))\n",
    "        step += 1\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_step = 1\n",
    "    \n",
    "    for x_test_batch, y_test_batch in test_batches:\n",
    "        f_ev = model.test_on_batch(x_test_batch, y_test_batch)\n",
    "        test_loss += f_ev[0]\n",
    "        test_loss_avg = test_loss / test_step\n",
    "        test_accuracy += f_ev[1]\n",
    "        test_accuracy_avg = test_accuracy / test_step\n",
    "        test_step += 1\n",
    "    stop = datetime.datetime.now()\n",
    "    e_elap = stop - start\n",
    "    t_elap = stop - initial\n",
    "    print('Epoch {}. Loss: {}. Accuracy: {}\\nEpoch time: {}. Total time: {}\\n'.format(e, test_loss_avg, test_accuracy_avg, e_elap, t_elap))\n",
    "\n",
    "if save:\n",
    "    print('Saving model params...')\n",
    "    json_string = model.to_json()\n",
    "    with open(model_name_path, 'w') as f:\n",
    "        json.dump(json_string, f)\n",
    "\n",
    "model.save_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del trainX, trainY, valX, valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_weights_path)\n",
    "\n",
    "#from keras.optimizers import SGD\n",
    "#sgd = SGD(lr=0.01, momentum=0.9, nesterov= True)\n",
    "\n",
    "# Compile model again (required to make predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 1\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (176, 2)\n",
      "Found 176 texts.\n"
     ]
    }
   ],
   "source": [
    "(testX, testY) = data_helpers.load_doc_data(authors = authorlist, docID = doc_id)\n",
    "testX = data_helpers.encode_data(testX, maxlen, vocab, vocab_size, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predY = np.array(model.predict(testX, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.96111631e-01,   3.22959828e-03,   6.58770441e-04],\n",
       "       [  9.99935567e-01,   6.06235335e-05,   3.82875623e-06],\n",
       "       [  9.99912083e-01,   8.10839119e-05,   6.83532789e-06],\n",
       "       [  9.99967515e-01,   3.20289510e-05,   4.46864306e-07],\n",
       "       [  9.99951184e-01,   3.67558459e-05,   1.20756558e-05],\n",
       "       [  9.99915481e-01,   6.57606070e-05,   1.87502992e-05],\n",
       "       [  9.99930978e-01,   6.57179917e-05,   3.32806167e-06],\n",
       "       [  9.99993145e-01,   3.86129386e-06,   3.00916099e-06],\n",
       "       [  9.99979317e-01,   1.25179258e-05,   8.16534066e-06],\n",
       "       [  9.99997199e-01,   1.52635982e-06,   1.28878150e-06],\n",
       "       [  9.99995589e-01,   3.16619594e-06,   1.21529229e-06],\n",
       "       [  9.99998331e-01,   9.21945457e-07,   7.18176182e-07],\n",
       "       [  9.99988854e-01,   1.03585426e-05,   7.93583638e-07],\n",
       "       [  9.99986887e-01,   6.66240567e-06,   6.42273017e-06],\n",
       "       [  9.99995768e-01,   3.04454124e-06,   1.19496406e-06],\n",
       "       [  9.99867082e-01,   1.30398039e-04,   2.52412906e-06],\n",
       "       [  9.99840438e-01,   1.48851075e-04,   1.07292317e-05],\n",
       "       [  9.99891639e-01,   1.05002306e-04,   3.36764447e-06],\n",
       "       [  9.99977589e-01,   2.12446485e-05,   1.14101715e-06],\n",
       "       [  9.99984562e-01,   9.42822862e-06,   6.00518433e-06],\n",
       "       [  9.99987364e-01,   9.16463978e-06,   3.45034255e-06],\n",
       "       [  9.99992430e-01,   6.19159346e-06,   1.35637822e-06],\n",
       "       [  9.99998033e-01,   1.66447978e-06,   2.88147987e-07],\n",
       "       [  9.99964535e-01,   3.35117038e-05,   1.95474377e-06],\n",
       "       [  9.99997497e-01,   1.96743417e-06,   5.22537164e-07],\n",
       "       [  9.99999106e-01,   4.16122390e-07,   4.92884396e-07],\n",
       "       [  9.99998271e-01,   9.37268965e-07,   7.83467840e-07],\n",
       "       [  9.99996245e-01,   1.36726669e-06,   2.38911935e-06],\n",
       "       [  9.99995768e-01,   2.46091690e-06,   1.76307742e-06],\n",
       "       [  9.99981463e-01,   1.30695644e-05,   5.44923341e-06],\n",
       "       [  9.99995232e-01,   3.32145510e-06,   1.45983358e-06],\n",
       "       [  9.99990344e-01,   8.48646232e-06,   1.15225782e-06],\n",
       "       [  9.99996960e-01,   1.21967582e-06,   1.82499696e-06],\n",
       "       [  9.99580562e-01,   4.09842207e-04,   9.61657042e-06],\n",
       "       [  9.99994814e-01,   3.74896968e-06,   1.44049352e-06],\n",
       "       [  9.99992907e-01,   5.17208355e-06,   1.90597405e-06],\n",
       "       [  9.99257326e-01,   7.35482376e-04,   7.16818158e-06],\n",
       "       [  9.99957800e-01,   3.44173059e-05,   7.76870002e-06],\n",
       "       [  9.99842584e-01,   1.53006171e-04,   4.40351232e-06],\n",
       "       [  9.99988317e-01,   9.41827057e-06,   2.27040505e-06],\n",
       "       [  9.99991119e-01,   6.62299863e-06,   2.23605002e-06],\n",
       "       [  9.99806225e-01,   1.57352042e-04,   3.64194129e-05],\n",
       "       [  9.95312929e-01,   4.66565602e-03,   2.14398788e-05],\n",
       "       [  9.98712361e-01,   1.27788237e-03,   9.74990689e-06],\n",
       "       [  9.99960363e-01,   3.58424586e-05,   3.80565439e-06],\n",
       "       [  9.99854922e-01,   1.39723634e-04,   5.34643686e-06],\n",
       "       [  9.99995530e-01,   3.50350615e-06,   9.94281095e-07],\n",
       "       [  9.99994278e-01,   4.61572245e-06,   1.12118948e-06],\n",
       "       [  9.99226391e-01,   7.64103082e-04,   9.49089736e-06],\n",
       "       [  9.99977827e-01,   1.88960312e-05,   3.29600266e-06],\n",
       "       [  9.99979019e-01,   1.65847396e-05,   4.39182440e-06],\n",
       "       [  9.99965191e-01,   2.79234046e-05,   6.86833755e-06],\n",
       "       [  9.99991119e-01,   6.68692155e-06,   2.21797382e-06],\n",
       "       [  9.99996483e-01,   3.28205897e-06,   2.62445383e-07],\n",
       "       [  9.99988735e-01,   1.05529789e-05,   6.92891831e-07],\n",
       "       [  9.99995887e-01,   3.18301181e-06,   9.22458582e-07],\n",
       "       [  9.99997616e-01,   2.13852604e-06,   2.57806789e-07],\n",
       "       [  9.99984026e-01,   1.11898244e-05,   4.75817023e-06],\n",
       "       [  9.99992609e-01,   6.02320233e-06,   1.37071231e-06],\n",
       "       [  9.99989927e-01,   3.30848866e-06,   6.74786861e-06],\n",
       "       [  9.99951363e-01,   4.31870576e-05,   5.47726631e-06],\n",
       "       [  9.99980986e-01,   1.66400951e-05,   2.35803577e-06],\n",
       "       [  9.99998331e-01,   1.21013977e-06,   4.76354785e-07],\n",
       "       [  9.99987662e-01,   6.79245477e-06,   5.52045231e-06],\n",
       "       [  9.99619305e-01,   3.72607319e-04,   8.07213928e-06],\n",
       "       [  9.98928905e-01,   1.03705819e-03,   3.40382212e-05],\n",
       "       [  9.99441087e-01,   4.88043006e-04,   7.08923326e-05],\n",
       "       [  9.99936283e-01,   5.95383317e-05,   4.17575257e-06],\n",
       "       [  9.99992728e-01,   4.79598293e-06,   2.49410050e-06],\n",
       "       [  9.99883890e-01,   1.13225957e-04,   2.87009516e-06],\n",
       "       [  9.99993742e-01,   4.83273197e-06,   1.43650539e-06],\n",
       "       [  9.99993324e-01,   2.95508767e-06,   3.72561908e-06],\n",
       "       [  9.99985278e-01,   8.42434565e-06,   6.26833980e-06],\n",
       "       [  9.99993384e-01,   2.32222851e-06,   4.28074145e-06],\n",
       "       [  9.99995708e-01,   2.82849214e-06,   1.43474483e-06],\n",
       "       [  9.99977887e-01,   1.78251958e-05,   4.28973908e-06],\n",
       "       [  9.99999106e-01,   4.20303792e-07,   4.59081122e-07],\n",
       "       [  9.99683797e-01,   3.09035968e-04,   7.19363879e-06],\n",
       "       [  9.99991238e-01,   8.09143148e-06,   6.50360391e-07],\n",
       "       [  9.99825954e-01,   1.60041178e-04,   1.39958629e-05],\n",
       "       [  9.99995172e-01,   3.53815653e-06,   1.28226429e-06],\n",
       "       [  9.99997318e-01,   2.00001250e-06,   6.62241746e-07],\n",
       "       [  9.98984337e-01,   1.01245358e-03,   3.19072774e-06],\n",
       "       [  9.99963880e-01,   3.40790430e-05,   2.06607911e-06],\n",
       "       [  9.99956667e-01,   3.64499138e-05,   6.85425039e-06],\n",
       "       [  9.99944508e-01,   4.85402124e-05,   6.93861330e-06],\n",
       "       [  9.99961436e-01,   3.53065370e-05,   3.28706528e-06],\n",
       "       [  9.99990225e-01,   7.59967361e-06,   2.18291075e-06],\n",
       "       [  9.99994576e-01,   1.15660816e-06,   4.26082988e-06],\n",
       "       [  9.99938190e-01,   5.71834535e-05,   4.63134074e-06],\n",
       "       [  9.99996960e-01,   2.44998409e-06,   6.01036049e-07],\n",
       "       [  9.99995768e-01,   2.79783831e-06,   1.42708393e-06],\n",
       "       [  9.99998271e-01,   1.08097220e-06,   6.49326921e-07],\n",
       "       [  9.99929965e-01,   6.83623584e-05,   1.67754820e-06],\n",
       "       [  9.99981523e-01,   1.69642080e-05,   1.49960158e-06],\n",
       "       [  9.99987960e-01,   7.01279896e-06,   5.02255853e-06],\n",
       "       [  9.99949455e-01,   2.68846943e-05,   2.36350115e-05],\n",
       "       [  9.99965608e-01,   2.89863456e-05,   5.39809116e-06],\n",
       "       [  9.99993026e-01,   5.93519826e-06,   1.04746391e-06],\n",
       "       [  9.99997973e-01,   1.79876906e-06,   2.33813580e-07],\n",
       "       [  9.99977350e-01,   2.21764640e-05,   4.82882740e-07],\n",
       "       [  9.99993682e-01,   4.43092995e-06,   1.90830906e-06],\n",
       "       [  9.99976218e-01,   1.91974523e-05,   4.58900558e-06],\n",
       "       [  9.99958038e-01,   2.40156332e-05,   1.79509098e-05],\n",
       "       [  9.99993622e-01,   4.15595650e-06,   2.19336266e-06],\n",
       "       [  9.99992549e-01,   5.54043663e-06,   1.92006314e-06],\n",
       "       [  9.99990880e-01,   6.42405439e-06,   2.67252790e-06],\n",
       "       [  9.99993563e-01,   5.24732150e-06,   1.16074523e-06],\n",
       "       [  9.99996722e-01,   1.44714977e-06,   1.80895961e-06],\n",
       "       [  9.99993384e-01,   4.36373966e-06,   2.28174281e-06],\n",
       "       [  9.99998808e-01,   6.20456888e-07,   5.58394390e-07],\n",
       "       [  9.99995768e-01,   3.67049915e-06,   5.59129660e-07],\n",
       "       [  9.99994397e-01,   3.55734073e-06,   2.05878382e-06],\n",
       "       [  9.99988735e-01,   2.56562134e-06,   8.69691667e-06],\n",
       "       [  9.99959409e-01,   2.15923956e-05,   1.90193641e-05],\n",
       "       [  9.99988139e-01,   9.68043332e-06,   2.17714933e-06],\n",
       "       [  9.99997318e-01,   1.32150399e-06,   1.33727531e-06],\n",
       "       [  9.99984682e-01,   1.11065110e-05,   4.24144946e-06],\n",
       "       [  9.99521375e-01,   4.72895452e-04,   5.75880722e-06],\n",
       "       [  9.99994516e-01,   4.49219897e-06,   9.62584409e-07],\n",
       "       [  9.99998391e-01,   9.88863576e-07,   6.40555072e-07],\n",
       "       [  9.99984741e-01,   9.87477506e-06,   5.41042982e-06],\n",
       "       [  9.99949276e-01,   4.46024678e-05,   6.12058420e-06],\n",
       "       [  9.99975264e-01,   1.95490920e-05,   5.20437561e-06],\n",
       "       [  9.99998748e-01,   1.07849723e-06,   1.53900359e-07],\n",
       "       [  9.99988019e-01,   1.08840741e-05,   1.12038299e-06],\n",
       "       [  9.99970615e-01,   1.95635857e-05,   9.84843427e-06],\n",
       "       [  9.99997973e-01,   9.68983386e-07,   1.03247646e-06],\n",
       "       [  9.99974370e-01,   2.34551535e-05,   2.18769446e-06],\n",
       "       [  9.99758005e-01,   2.33592466e-04,   8.42140344e-06],\n",
       "       [  9.99940932e-01,   5.77190149e-05,   1.32090906e-06],\n",
       "       [  9.99968708e-01,   2.97489150e-05,   1.54687291e-06],\n",
       "       [  9.99982238e-01,   1.54010431e-05,   2.35662696e-06],\n",
       "       [  9.99922931e-01,   7.43144774e-05,   2.78082325e-06],\n",
       "       [  9.99983191e-01,   1.10112387e-05,   5.78808431e-06],\n",
       "       [  9.99985576e-01,   1.25659199e-05,   1.86712327e-06],\n",
       "       [  9.99902666e-01,   6.49709618e-05,   3.23498680e-05],\n",
       "       [  9.99993742e-01,   2.82088968e-06,   3.46680326e-06],\n",
       "       [  9.99822915e-01,   1.48257561e-04,   2.88434858e-05],\n",
       "       [  9.99990880e-01,   5.83552855e-06,   3.28342117e-06],\n",
       "       [  9.99967456e-01,   2.70478649e-05,   5.50492587e-06],\n",
       "       [  9.99692678e-01,   2.98652361e-04,   8.66208211e-06],\n",
       "       [  9.99971509e-01,   2.50477297e-05,   3.42619410e-06],\n",
       "       [  9.99941409e-01,   5.60066874e-05,   2.59471153e-06],\n",
       "       [  9.99945939e-01,   5.05295320e-05,   3.55279167e-06],\n",
       "       [  9.99909401e-01,   8.31540601e-05,   7.45495163e-06],\n",
       "       [  9.99983728e-01,   1.21789244e-05,   4.07223752e-06],\n",
       "       [  9.99974608e-01,   2.00608447e-05,   5.35353684e-06],\n",
       "       [  9.99989390e-01,   8.95282028e-06,   1.67747032e-06],\n",
       "       [  9.99995828e-01,   2.76551691e-06,   1.43641523e-06],\n",
       "       [  9.99986887e-01,   1.16204728e-05,   1.48416416e-06],\n",
       "       [  9.99984622e-01,   1.46814409e-05,   7.07503659e-07],\n",
       "       [  9.99981046e-01,   1.71479860e-05,   1.82712381e-06],\n",
       "       [  9.99968052e-01,   2.41023536e-05,   7.81605831e-06],\n",
       "       [  9.99991000e-01,   6.82414975e-06,   2.19430240e-06],\n",
       "       [  9.99994934e-01,   1.46988316e-06,   3.58737748e-06],\n",
       "       [  9.99020040e-01,   9.69117566e-04,   1.08162631e-05],\n",
       "       [  9.99996424e-01,   3.00914780e-06,   5.93143511e-07],\n",
       "       [  9.99998927e-01,   6.93020468e-07,   3.86545537e-07],\n",
       "       [  9.99991238e-01,   7.68532027e-06,   1.06022162e-06],\n",
       "       [  9.99925971e-01,   5.97896142e-05,   1.42109247e-05],\n",
       "       [  9.99984384e-01,   1.41668543e-05,   1.47767787e-06],\n",
       "       [  9.99985754e-01,   1.20396098e-05,   2.19324511e-06],\n",
       "       [  9.99997675e-01,   1.80714903e-06,   4.90118225e-07],\n",
       "       [  9.99997258e-01,   2.01892499e-06,   7.23919982e-07],\n",
       "       [  9.99930084e-01,   6.80292505e-05,   1.87740397e-06],\n",
       "       [  9.99985278e-01,   1.19707038e-05,   2.72620105e-06],\n",
       "       [  9.99677122e-01,   3.18387611e-04,   4.51463075e-06],\n",
       "       [  9.99993384e-01,   5.61922252e-06,   1.00819386e-06],\n",
       "       [  9.99981701e-01,   1.52501443e-05,   3.07071286e-06],\n",
       "       [  9.99995708e-01,   3.53581413e-06,   7.36676441e-07],\n",
       "       [  9.99973655e-01,   2.47973894e-05,   1.56355713e-06],\n",
       "       [  9.99996245e-01,   3.25259998e-06,   5.26981466e-07],\n",
       "       [  9.99991179e-01,   8.32449314e-06,   5.01210252e-07],\n",
       "       [  9.99839187e-01,   1.58521536e-04,   2.27486476e-06],\n",
       "       [  9.99977648e-01,   1.65897945e-05,   5.76466755e-06]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
