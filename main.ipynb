{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "import py_crepe\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_helpers\n",
    "import data\n",
    "import string\n",
    "import pandas as pd\n",
    "np.random.seed(0123)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "subset = None\n",
    "\n",
    "#Whether to save model parameters\n",
    "save = False\n",
    "model_name_path = 'params/crepe_model.json'\n",
    "model_weights_path = 'params/crepe_model_weights.h5'\n",
    "\n",
    "#Maximum length. Longer gets chopped. Shorter gets padded.\n",
    "maxlen = 1014\n",
    "\n",
    "#Model params\n",
    "#Filters for conv layers\n",
    "nb_filter = 128 #initially 256\n",
    "#Number of units in the dense layer\n",
    "dense_outputs = 512 #Initially 1024\n",
    "#Conv layer kernel size\n",
    "filter_kernels = [7, 7, 3, 3, 3, 3]\n",
    "#Number of units in the final output layer. Number of classes.\n",
    "\n",
    "#Compile/fit params\n",
    "batch_size = 32\n",
    "nb_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 33\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (4589, 2)\n",
      "Author:   104  Size:  2212\n",
      "Author:  1430  Size:  1143\n",
      "Author:  1610  Size:  1234\n",
      "Min: 1143\n",
      "Max: 2212\n",
      "Authors [104, 1430, 1610].\n",
      "Found 3429 texts.\n",
      "Found 3429 labels.\n",
      "Creating vocab...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "#Expect x to be a list of sentences. Y to be a one-hot encoding of the\n",
    "#categories.\n",
    "\n",
    "### 515-1122-122 and 1573 with remove 6 layers\n",
    "#authorlist=[121, 479 , 649 ]\n",
    "#doc_id = 1470\n",
    "\n",
    "authorlist=[ 104, 1430 , 1610]\n",
    "doc_id = 3845\n",
    "cat_output = len(authorlist) #binary in the last layer\n",
    "\n",
    "# def main(authorlist, doc_id):\n",
    "    \n",
    "    \n",
    "((trainX, trainY), (valX, valY)) = data_helpers.load_ag_data(authors = authorlist, docID = doc_id)\n",
    "\n",
    "print('Creating vocab...')\n",
    "vocab, reverse_vocab, vocab_size, check = data_helpers.create_vocab_set()\n",
    "\n",
    "\n",
    "#trainX = data_helpers.encode_data(trainX, maxlen, vocab, vocab_size, check)\n",
    "#test_data = data_helpers.encode_data(valX, maxlen, vocab, vocab_size, check)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "classes = len(authorlist)\n",
    "\n",
    "model = py_crepe.model(classes, filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model...\n",
      "Epoch: 0\n",
      "Epoch 0. Loss: 0.699053371494. Accuracy: 0.750608766621\n",
      "Epoch time: 0:03:57.297824. Total time: 0:03:57.381214\n",
      "\n",
      "Epoch: 1\n",
      "Epoch 1. Loss: 0.301732566208. Accuracy: 0.892045454545\n",
      "Epoch time: 0:03:53.313655. Total time: 0:07:50.759249\n",
      "\n",
      "Epoch: 2\n",
      "Epoch 2. Loss: 0.168360232968. Accuracy: 0.938514609228\n",
      "Epoch time: 0:03:52.478290. Total time: 0:11:43.302618\n",
      "\n",
      "Epoch: 3\n",
      "Epoch 3. Loss: 0.127565243366. Accuracy: 0.950284090909\n",
      "Epoch time: 0:03:53.995484. Total time: 0:15:37.364066\n",
      "\n",
      "Epoch: 4\n",
      "Epoch 4. Loss: 0.0891448812009. Accuracy: 0.96875\n",
      "Epoch time: 0:03:57.517184. Total time: 0:19:34.946098\n",
      "\n",
      "Epoch: 5\n",
      "Epoch 5. Loss: 0.103640308011. Accuracy: 0.963676948439\n",
      "Epoch time: 0:03:53.844374. Total time: 0:23:28.854739\n",
      "\n",
      "Epoch: 6\n",
      "Epoch 6. Loss: 0.108765895902. Accuracy: 0.961241881956\n",
      "Epoch time: 0:03:57.289922. Total time: 0:27:26.209448\n",
      "\n",
      "Epoch: 7\n",
      "Epoch 7. Loss: 0.0858706858271. Accuracy: 0.967329545455\n",
      "Epoch time: 0:03:56.769772. Total time: 0:31:23.044480\n",
      "\n",
      "Epoch: 8\n",
      "Epoch 8. Loss: 0.0778444664002. Accuracy: 0.977272727273\n",
      "Epoch time: 0:03:57.329589. Total time: 0:35:20.444116\n",
      "\n",
      "Epoch: 9\n",
      "Epoch 9. Loss: 0.0913567200107. Accuracy: 0.974025972865\n",
      "Epoch time: 0:03:56.652133. Total time: 0:39:17.163160\n",
      "\n",
      "Epoch: 10\n",
      "Epoch 10. Loss: 0.110904513139. Accuracy: 0.965909090909\n",
      "Epoch time: 0:03:56.945473. Total time: 0:43:14.173563\n",
      "\n",
      "Epoch: 11\n",
      "Epoch 11. Loss: 0.0740271706071. Accuracy: 0.980113636364\n",
      "Epoch time: 0:04:02.364365. Total time: 0:47:16.603776\n",
      "\n",
      "Epoch: 12\n",
      "Epoch 12. Loss: 0.075386196367. Accuracy: 0.980113636364\n",
      "Epoch time: 0:04:02.638530. Total time: 0:51:19.311543\n",
      "\n",
      "Epoch: 13\n",
      "Epoch 13. Loss: 0.0765414558859. Accuracy: 0.981534090909\n",
      "Epoch time: 0:04:02.649179. Total time: 0:55:22.026062\n",
      "\n",
      "Epoch: 14\n",
      "Epoch 14. Loss: 0.0732952560859. Accuracy: 0.980113636364\n",
      "Epoch time: 0:04:07.387951. Total time: 0:59:29.477541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fit model...')\n",
    "initial = datetime.datetime.now()\n",
    "for e in xrange(nb_epoch):\n",
    "    xi, yi = data_helpers.shuffle_matrix(trainX, trainY)\n",
    "    xi_test, yi_test = data_helpers.shuffle_matrix(valX, valY)\n",
    "    if subset:\n",
    "        batches = data_helpers.mini_batch_generator(xi[:subset], yi[:subset],\n",
    "                                                    vocab, vocab_size, check,\n",
    "                                                    maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "    else:\n",
    "        batches = data_helpers.mini_batch_generator(xi, yi, vocab, vocab_size,\n",
    "                                                    check, maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "    test_batches = data_helpers.mini_batch_generator(xi_test, yi_test, vocab,\n",
    "                                                     vocab_size, check, maxlen,\n",
    "                                                     batch_size=batch_size)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    loss = 0.0\n",
    "    step = 1\n",
    "    start = datetime.datetime.now()\n",
    "    print('Epoch: {}'.format(e))\n",
    "    for x_train, y_train in batches:\n",
    "        \n",
    "        f = model.train_on_batch(x_train, y_train)\n",
    "        loss += f[0]\n",
    "        loss_avg = loss / step\n",
    "        accuracy += f[1]\n",
    "        accuracy_avg = accuracy / step\n",
    "        if step % 100 == 0:\n",
    "            print('  Step: {}'.format(step))\n",
    "            print('\\tLoss: {}. Accuracy: {}'.format(loss_avg, accuracy_avg))\n",
    "        step += 1\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_step = 1\n",
    "    \n",
    "    for x_test_batch, y_test_batch in test_batches:\n",
    "        f_ev = model.test_on_batch(x_test_batch, y_test_batch)\n",
    "        test_loss += f_ev[0]\n",
    "        test_loss_avg = test_loss / test_step\n",
    "        test_accuracy += f_ev[1]\n",
    "        test_accuracy_avg = test_accuracy / test_step\n",
    "        test_step += 1\n",
    "    stop = datetime.datetime.now()\n",
    "    e_elap = stop - start\n",
    "    t_elap = stop - initial\n",
    "    print('Epoch {}. Loss: {}. Accuracy: {}\\nEpoch time: {}. Total time: {}\\n'.format(e, test_loss_avg, test_accuracy_avg, e_elap, t_elap))\n",
    "\n",
    "if save:\n",
    "    print('Saving model params...')\n",
    "    json_string = model.to_json()\n",
    "    with open(model_name_path, 'w') as f:\n",
    "        json.dump(json_string, f)\n",
    "\n",
    "model.save_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
